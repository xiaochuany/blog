---
date: 
    created: 2025-08-01
authors: [xy]
categories: [TIL]
tags: [dev tools]
---

# dataiku productivity patterns
<!-- more -->


## Feed partition numbers with code

To programmatically feed partition numbers, do

```py
import dataiku as dk

p = dk.api_client().get_project("MYPROJECT")
p.get_recipe("MYRECIPE").run(partitions=...)
```

This is particularly useful when the UI cannot autocomplete the partition keys (e.g. discrete values).  

https://developer.dataiku.com/latest/concepts-and-examples/projects.html
https://developer.dataiku.com/latest/api-reference/python/projects.html#dataiku.Project


https://developer.dataiku.com/latest/concepts-and-examples/recipes.html
https://developer.dataiku.com/latest/api-reference/python/recipes.html

Seems possible to use the concept of jobs

https://developer.dataiku.com/latest/concepts-and-examples/jobs.html
https://developer.dataiku.com/latest/api-reference/python/projects.html#dataikuapi.dss.project.DSSProject.list_jobs

## Access custom variables

There 
are numerous ways of accessing/defining variables, it seems that the one in the dataiku namespace is the most reasonable

```py
import dataiku as dk

dk.get_custom_variables() 
```

Indeed, one gets the project level variables like this 

```py
dk.api_client().project("MYPROJECT").get_variables()
```

but what's returned is a nested dictionary, with standard variables dict and local variables dict inside it. 

As far as I can tell, `dk.get_custom_variables` has everything in it, containing both standard and local variables, and it is a flat dictionary. I prefer this one over the project-level variables dict. 


Yet another kind of variables are runtime variables. If we call the below in a notebook we get `None`. It may come in handy in a SQL/Python recipe and can be used to refer to a column that is the partition key (be it in the input table or the ouput table). 

```py
dk.dku_flow_variables 
```

Examples from the official docs. More details see below. 

![alt text](assets/2025-08-01-scenario-1754080203195.png)

![alt text](assets/2025-08-01-scenario-1754080217785.png)


## Partition SQL query **dataset** and provide partition identifiers (or write a query to retrieve them): 

![alt text](assets/2025-08-01-dataiku-1754253620803.png)

![alt text](assets/2025-08-01-dataiku-1754253733013.png)

grammer for partition identifiers

https://doc.dataiku.com/dss/latest/partitions/identifiers.html

## SQL **recipe** that takes as input a partitioned dataset 

![alt text](assets/2025-08-01-dataiku-1754253891884.png)

if I want to partition the output on a  columns that is not necessarily the input partition key

![alt text](assets/2025-08-01-dataiku-1754254102886.png)

## Python recipe that takes as input a partitioned dataset 

![alt text](assets/2025-08-01-dataiku-1754254868742.png)

more rules about partition variable substitution

https://doc.dataiku.com/dss/latest/partitions/variables.html


## Partition dependency function 

Haven't use it in my projects but I can see it being flexible in specifying the dependency of input and output partitions. 

https://doc.dataiku.com/dss/latest/partitions/dependencies.html
